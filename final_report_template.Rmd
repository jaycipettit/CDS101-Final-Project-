---
title: "CDS 101 – Final Project Report"
author: "Group Name / Janet Tadesse, Jayci Pettit, Lauren Graczyk"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    css: "gmu-cds101.css"
    toc: true
    toc_depth: 3
    number_sections: true
  pdf_document:
    toc: true
---

> Replace this template text with your own writing, keeping the headings and overall structure aligned with the **CDS 101 project rubric**.

# 1. Problem Definition

The main problem or question we are investigating is if time of day impacts the sale of hot chocolate/cocoa drinks.  

This question is interesting because the general recommendation is to avoid caffeine later in the day.  Knowing this, we would expect to see hot cocoa sales improve later in the day as an decaffeinated option.  

Methods: Two-way hypothesis testing because we chose to examine categorical variables and want to note ANY change, positive or negative. 

Null hypothesis: Time of day does not impact the sales of hot chocolate/cocoa drinks. 

Alternative hypothesis: Time of day changes hot chocolate/cocoa drink sales. 

Expected result: We expect hot chocolate/cocoa sales to take up a larger portion of sales later in the day. 

# 2. Data Acquisition & Description

The name of the dataset is "Coffee shop sales" and it was retrieved from Kaggle. 
The file was downloaded directly from Kaggle.  
1. transaction_id

Unique identifier for each sales transaction.
Type: Integer
Units: None

2. transaction_date

The calendar date when the transaction occurred.
Type: Date
Units: YYYY-MM-DD

3. transaction_time

The time of day when the transaction was recorded.
Type: Time (POSIX time)
Units: YYYY-MM-DD HH:MM:SS

4. transaction_qty

Number of units/items purchased in the transaction.
Type: Integer
Units: Count

5. store_id

Unique code identifying the store where the transaction took place.
Type: Integer
Units: None

6. store_location

The name or geographic location of the store.
Type: Character (categorical)
Units: None

7. product_id

Unique identifier for the product sold.
Type: Integer
Units: None

8. unit_price

Price of a single unit of the product sold.
Type: Numeric
Units: Currency (USD)

9. product_category

Broad category of the product (e.g., Coffee, Tea, Hot cocoa).
Type: Character (categorical)
Units: None

10. product_type

More specific product grouping within each category (e.g., Latte, Iced Coffee).
Type: Character (categorical)
Units: None

11. product_detail

Detailed description of the product (e.g., “Vanilla Latte – Medium”).
Type: Character (categorical / descriptive text)
Units: None  

- The file contains 149116 rows and 11 columns.  
- There shouldn't be any ethical, privacy, or bias considerations.

```{r setup-data, echo=FALSE, message=FALSE, warning=FALSE}
library(readxl)

data <- read_excel("Coffee Shop Sales.xlsx")
class(data)
```

```{r}
dim(data)
names(data)
```

```{r}
data <- as.data.frame(data)
head(data)
```

# 3. Data Cleaning & Preprocessing

We create a new dataframe called coffee_sales that contains only the relevant columns for analysis: transaction_time, transaction_qty, product_category, product_type and product_detail.  Next, we took the transaction_time column and looked at the time specifically, using that to create a new column that filtered each transaction into morning, afternoon or evening categories based on the time.  Finally, we define a function remove_outliers() that identifies outliers using the interquartile range (IQR) method, which considers values outside 1.5 times the IQR above the third quartile or below the first quartile as outliers.  Using this function, we filter the original dataset to remove outliers in transaction_qty, resulting in a cleaner dataset data_no_outliers that is more suitable for analysis.

```{r cleaning, eval=FALSE}
library(dplyr)

coffee_sales <- data %>%
  select(transaction_time,
         transaction_date,
         transaction_qty,
         product_category,
         product_type,
         product_detail)
```

```{r}
library(dplyr)
library(lubridate)

coffee_sales <- coffee_sales %>%
  mutate(
    datetime = ymd_hms(transaction_time),
    hour = hour(datetime),   # extract hour (0–23)
    time_of_day = case_when(
      hour >= 0  & hour < 12 ~ "morning",
      hour >= 12 & hour < 17 ~ "afternoon",
      hour >= 17             ~ "evening",
      TRUE                   ~ NA_character_
    )
  ) %>%
  select(-datetime)
```

```{r}
head(coffee_sales)
```

```{r}
remove_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  
  x >= (Q1 - 1.5*IQR) & x <= (Q3 + 1.5*IQR)
}

coffee_sales <- coffee_sales %>%
  filter(remove_outliers(transaction_qty))
```

```{r}
head(coffee_sales)
```

```{r}
nrow(data)
# or if you're using a new dataset
nrow(data_no_outliers)

# 2. Optionally, check number of NAs
sum(is.na(data$transaction_time))
sum(is.na(data$transaction_date))

# 3. Show the structure
str(data)
```

```{r}
head(coffee_sales, 10)
```

# 4. Exploratory Data Analysis (EDA)

This section maps directly to the **EDA** part of the rubric:

- Summary statistics  
- Visualizations  
- Interpretation connected to the research question  

```{r eda-summary, message=FALSE, warning=FALSE}
library(dplyr)
summary(coffee_sales)
```

```{r}
library(ggplot2)

coffee_sales %>%
  filter(product_category == "Drinking Chocolate") %>%
  ggplot(aes(x = transaction_qty,)) +
    geom_histogram(binwidth = 1, color = "white", fill = "skyblue") +
    facet_wrap(~ time_of_day) +
    labs(
      x = "Hot Chocolate Orders",
      y = "Count",
      title = "Hot Cocoa Transaction Quantities by Time of Day"
    )
```

```{r}
library(ggplot2)

coffee_sales %>%
  filter(product_category == "Drinking Chocolate") %>%
  ggplot(aes(x = time_of_day)) +
    geom_bar(fill = "green", color = "black") +
    labs(
      x = "Time of Day",
      y = "Number of Hot Cocoa Transactions",
      title = "Hot Cocoa Sales by Time of Day"
    ) +
    theme_minimal()

```

```{r}
library(ggplot2)

coffee_sales %>%
  count(time_of_day, product_category) %>%
  ggplot(aes(x = time_of_day, y = n, fill = product_category)) +
    geom_bar(stat = "identity", position = "fill") +
    labs(
      x = "Time of Day",
      y = "Percentage of Sales",
      title = "Total Product Sales by Time of Day"
    ) +
    theme_minimal()

```
```{r eda-plot-example, message=FALSE, warning=FALSE, fig.cap="Example histogram of a numeric variable (EDA rubric)."}
# library(ggplot2)
# ggplot(data_clean, aes(x = some_numeric_variable)) +
#   geom_histogram(binwidth = 5, color = "white") +
#   labs(x = "Some Variable", y = "Count", title = "Distribution of Some Variable")
```


# 5. Visualization Quality and Storytelling

Use this section to satisfy the **Visualization Quality** rubric criterion:

- Explain why your plot types are appropriate.  
- Comment on labels, legends, colors, and overall readability.  
- Mention any steps you took to make plots accessible and interpretable.

Our plot type is appropriate because we are not documenting a change over time. We want to count the number of items that occur within a certain time of day category and show the percentage of each total for product categories. This makes the plot more comprehansive and clearer for viewers because it accounts for varied sale volumes rather than producing a raw number. For example, if the morning had 100 sales and 50 of them were hot chocolate while the evening had 50 sales and 45 of them were hot chocolate, raw numbers would say there were fewer hot chocolate sales in the evening, which is true. However, it does not relay the fact that sales as a whole decreased in the evening and that hot chocolate went from comprising 50% of total sales to 90% of total sales, which paints a better picture for analysis. The plots are relatively easy to read, however, it would be more beneficial to see the percentages as numbers rather than colored bar sections. 

# 6. Modeling Approach

Explain how you framed the problem and which models you chose:

- Type of task (regression, classification, etc.).  
- Baseline model or heuristic, if used.  
- Main model(s) chosen and why they are appropriate.

# 7. Model Implementation & Evaluation

This corresponds to the **Model Implementation & Evaluation** rubric criterion.

Describe:

- Features used.  
- Data splitting strategy (train/test or cross-validation).  
- Metrics used (accuracy, F1, RMSE, etc.).  
- Tables/plots summarizing performance.  
- A short interpretation of each metric/plot.

```{r modeling, eval=FALSE}
# Example structure:
# set.seed(123)
# train_index <- sample(seq_len(nrow(data_clean)), size = 0.8 * nrow(data_clean))
# train <- data_clean[train_index, ]
# test  <- data_clean[-train_index, ]
#
# model <- glm(target ~ ., data = train, family = binomial)
# preds <- predict(model, newdata = test, type = "response")
# # compute metrics...
```

# 8. Conclusions & Recommendations

Summarize the key takeaways:

- Answer your original research question(s) directly.  
- Highlight the most important patterns or relationships you found.  
- Discuss limitations (data size, bias, missing variables, etc.).  
- Suggest possible extensions or future work.

# 9. Code Quality & Reproducibility

Briefly document how someone else can reproduce your results:

- Which R scripts or Rmd files to run.  
- Any required R packages.  

```{r session-info, echo=FALSE}
sessionInfo()
```

# 10. References

List any references you used, such as:

- Dataset documentation.  
- Research papers or articles.  
- Tutorials or blog posts.

# Appendix (Optional)

Include extra plots, diagnostic checks, or model comparisons if needed.
